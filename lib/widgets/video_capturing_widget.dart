import 'dart:io';
import 'dart:convert';
import 'package:flutter/material.dart';
import 'package:flutter_webrtc/flutter_webrtc.dart';
import 'package:ffmpeg_kit_flutter_new/ffmpeg_kit.dart';
import 'package:ffmpeg_kit_flutter_new/return_code.dart';
import 'package:ffmpeg_kit_flutter_new/ffmpeg_session.dart';
import 'package:path_provider/path_provider.dart';
import 'package:file_picker/file_picker.dart';
import 'package:path/path.dart' as path;
import 'package:shared_preferences/shared_preferences.dart';
import 'package:web_socket_channel/web_socket_channel.dart';
// Add this import

import '../modules/ApiService.dart';

// –ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ –¥–µ—Ç–µ–∫—Ü–∏–∏
class DetectionBox {
  final double x1;
  final double y1;
  final double x2;
  final double y2;
  final String label;
  final double confidence;
  final Duration timestamp; // –ò–∑–º–µ–Ω–∏–ª–∏ DateTime –Ω–∞ Duration

  DetectionBox({
    required this.x1,
    required this.y1,
    required this.x2,
    required this.y2,
    required this.label,
    required this.confidence,
    required this.timestamp,
  });

  factory DetectionBox.fromJson(Map<String, dynamic> json) {
    // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–∏ –≤ Duration
    Duration parseTimestamp(dynamic timestamp) {
      if (timestamp is int) {
        return Duration(milliseconds: timestamp);
      } else if (timestamp is double) {
        return Duration(milliseconds: timestamp.toInt());
      } else if (timestamp is String) {
        try {
          return Duration(milliseconds: int.parse(timestamp));
        } catch (e) {
          return Duration.zero;
        }
      } else {
        return Duration.zero;
      }
    }

    return DetectionBox(
      x1: _toDouble(json['x1']),
      y1: _toDouble(json['y1']),
      x2: _toDouble(json['x2']),
      y2: _toDouble(json['y2']),
      label: json['label']?.toString() ?? '',
      confidence: _toDouble(json['confidence']),
      timestamp: parseTimestamp(json['timestamp']),
    );
  }

  static double _toDouble(dynamic value) {
    if (value is double) return value;
    if (value is int) return value.toDouble();
    if (value is String) return double.tryParse(value) ?? 0.0;
    return 0.0;
  }

  // –ú–µ—Ç–æ–¥ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ –∫–æ–º–∞–Ω–¥—É drawbox FFmpeg —Å —Ç–æ—á–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º
  String toFFmpegDrawbox({double? startTime, double? endTime}) {
    final width = x2 - x1;
    final height = y2 - y1;
    String filter = "drawbox=x=${x1.toInt()}:y=${y1.toInt()}:w=${width.toInt()}:h=${height.toInt()}:color=red@0.5:thickness=3";
    if (startTime != null && endTime != null) {
      filter += ":enable='between(t,$startTime,$endTime)'";
    }
    return filter;
  }

// –ú–µ—Ç–æ–¥ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∏–ª—å—Ç—Ä–∞ —Å —Ç–æ—á–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º
  String toFFmpegDrawtext({double? startTime, double? endTime}) {
    String filter = "drawtext=text='$label ${(confidence * 100).toInt()}%':x=${x1.toInt()}:y=${(y1 - 20).toInt()}:fontsize=16:fontcolor=red:box=1:boxcolor=white@0.8";
    if (startTime != null && endTime != null) {
      filter += ":enable='between(t,$startTime,$endTime)'";
    }
    return filter;
  }
}

// CustomPainter –¥–ª—è –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤ –¥–µ—Ç–µ–∫—Ü–∏–∏
class DetectionOverlayPainter extends CustomPainter {
  final List<DetectionBox> detections;
  final Size videoSize;

  DetectionOverlayPainter({
    required this.detections,
    required this.videoSize,
  });

  @override
  void paint(Canvas canvas, Size size) {
    if (detections.isEmpty || videoSize.width == 0 || videoSize.height == 0) return;

    // –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Å—à—Ç–∞–± –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    final scaleX = size.width / videoSize.width;
    final scaleY = size.height / videoSize.height;

    for (var detection in detections) {
      // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
      final left = detection.x1 * scaleX;
      final top = detection.y1 * scaleY;
      final right = detection.x2 * scaleX;
      final bottom = detection.y2 * scaleY;

      // –†–∏—Å—É–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
      final paint = Paint()
        ..color = Colors.red
        ..style = PaintingStyle.stroke
        ..strokeWidth = 2.0;

      final rect = Rect.fromLTRB(left, top, right, bottom);
      canvas.drawRect(rect, paint);

      // –†–∏—Å—É–µ–º –ø–æ–¥–ø–∏—Å—å
      final textPainter = TextPainter(
        text: TextSpan(
          text: '${detection.label} ${(detection.confidence * 100).toStringAsFixed(1)}%',
          style: const TextStyle(
            color: Colors.red,
            fontSize: 12,
            fontWeight: FontWeight.bold,
            backgroundColor: Colors.white,
          ),
        ),
        textDirection: TextDirection.ltr,
      );

      textPainter.layout();

      // –ü–æ–∑–∏—Ü–∏—è –¥–ª—è —Ç–µ–∫—Å—Ç–∞ (–Ω–∞–¥ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–º)
      final textOffset = Offset(
        left,
        (top - textPainter.height - 2).clamp(0, size.height - textPainter.height),
      );

      // –†–∏—Å—É–µ–º —Ñ–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
      final textBackgroundPaint = Paint()..color = Colors.white.withOpacity(0.8);
      canvas.drawRect(
        Rect.fromLTWH(
          textOffset.dx,
          textOffset.dy,
          textPainter.width,
          textPainter.height,
        ),
        textBackgroundPaint,
      );

      textPainter.paint(canvas, textOffset);
    }
  }

  @override
  bool shouldRepaint(covariant CustomPainter oldDelegate) {
    return oldDelegate is! DetectionOverlayPainter ||
        oldDelegate.detections != detections ||
        oldDelegate.videoSize != videoSize;
  }
}

class CameraStreamWidget extends StatefulWidget {
  final double? width;
  final double? height;
  final double aspectRatio;
  final int videoWidth;
  final int videoHeight;
  final int frameRate;
  final Function(String, List<DetectionBox>)? onVideoCaptured;
  final Function()? startCaptured;
  final String? examinationId;

  const CameraStreamWidget({
    super.key,
    this.width,
    this.height,
    this.aspectRatio = 16 / 9,
    this.videoWidth = 1280,
    this.videoHeight = 720,
    this.frameRate = 30,
    this.onVideoCaptured,
    this.startCaptured,
    this.examinationId,
  });

  @override
  State<CameraStreamWidget> createState() => _CameraStreamWidgetState();
}

class _CameraStreamWidgetState extends State<CameraStreamWidget> {
  final RTCVideoRenderer _renderer = RTCVideoRenderer();
  MediaStream? _mediaStream;
  bool _isRecording = false;
  String? _outputPath;
  FFmpegSession? _ffmpegSession;

  List<MediaDeviceInfo> _videoDevices = [];
  List<MediaDeviceInfo> _audioDevices = [];
  String? _selectedVideoDeviceId;
  String? _selectedAudioDeviceId;
  String? _defaultSaveFolder;
  SharedPreferences? _prefs;

  // –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏
  WebSocketChannel? _webSocketChannel;
  List<DetectionBox> _currentDetections = [];
  List<DetectionBox> _allDetections = [];
  bool _isDetectionEnabled = false;
  DateTime? _recordingStartTime;

  @override
  void initState() {
    super.initState();
    _initializeSettings();
    _listAvailableDevices();

    // –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ WebSocket –µ—Å–ª–∏ –µ—Å—Ç—å examination ID
    if (widget.examinationId != null) {
      _connectToCameraStream(widget.examinationId!);
    }
  }

  // –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ WebSocket
  void _connectToCameraStream(String examinationId) {
    try {
      _webSocketChannel = WebSocketChannel.connect(
        Uri.parse('ws://127.0.0.1:8000/ws/camera/$examinationId'),
      );

      _webSocketChannel!.stream.listen((message) {
        try {
          final data = jsonDecode(message);
          final detections = data['detections'] as List<dynamic>? ?? [];

          final newDetections = detections
              .map((det) => DetectionBox.fromJson(det))
              .toList();

          setState(() {
            _currentDetections = newDetections;
          });

          // –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å —Ç–æ—á–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º –≤–æ –≤—Ä–µ–º—è –∑–∞–ø–∏—Å–∏
          if (_isRecording && _recordingStartTime != null) {
            final currentTime = DateTime.now();
            final relativeTime = currentTime.difference(_recordingStartTime!);

            for (final detection in newDetections) {
              final preciseDetection = DetectionBox(
                x1: detection.x1,
                y1: detection.y1,
                x2: detection.x2,
                y2: detection.y2,
                label: detection.label,
                confidence: detection.confidence,
                timestamp: relativeTime, // –¢–æ—á–Ω–æ–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
              );
              _allDetections.add(preciseDetection);
            }
          }
        } catch (e) {
          print('Error parsing detection data: $e');
        }
      });
    } catch (e) {
      print('Failed to connect to WebSocket: $e');
    }
  }

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏
  void _toggleDetection() {
    setState(() {
      _isDetectionEnabled = !_isDetectionEnabled;
      if (!_isDetectionEnabled) {
        _currentDetections.clear();
      }
    });
  }

  Future<void> _initializeSettings() async {
    _prefs = await SharedPreferences.getInstance();
    setState(() {
      _defaultSaveFolder = _prefs?.getString('default_save_folder');
      _selectedVideoDeviceId = _prefs?.getString('selected_video_device_id');
      _selectedAudioDeviceId = _prefs?.getString('selected_audio_device_id');
    });
  }

  Future<void> _saveSettings() async {
    await _prefs?.setString('default_save_folder', _defaultSaveFolder ?? '');
    await _prefs?.setString('selected_video_device_id', _selectedVideoDeviceId ?? '');
    await _prefs?.setString('selected_audio_device_id', _selectedAudioDeviceId ?? '');
  }

  Future<void> _listAvailableDevices() async {
    try {
      final devices = await navigator.mediaDevices.enumerateDevices();
      setState(() {
        _videoDevices = devices.where((device) => device.kind == 'videoinput').toList();
        _audioDevices = devices.where((device) => device.kind == 'audioinput').toList();

        if (_selectedVideoDeviceId == null && _videoDevices.isNotEmpty) {
          _selectedVideoDeviceId = _videoDevices.first.deviceId;
        }
        if (_selectedAudioDeviceId == null && _audioDevices.isNotEmpty) {
          _selectedAudioDeviceId = _audioDevices.first.deviceId;
        }
      });

      await Future.delayed(const Duration(milliseconds: 300));
      await _initializeCamera();
    } catch (e) {
      print('Error listing devices: $e');
      setState(() {
        _selectedVideoDeviceId = null;
        _selectedAudioDeviceId = null;
      });
      await _initializeCamera();
    }
  }

  Future<void> _initializeCamera() async {
    await _renderer.initialize();

    final constraints = {
      'audio': _selectedAudioDeviceId != null,
      'video': {
        'deviceId': _selectedVideoDeviceId,
        'width': widget.videoWidth,
        'height': widget.videoHeight,
        'frameRate': widget.frameRate,
      },
    };

    try {
      _mediaStream?.getTracks().forEach((track) => track.stop());
      final stream = await navigator.mediaDevices.getUserMedia(constraints);
      _renderer.srcObject = stream;
      setState(() => _mediaStream = stream);
    } catch (e) {
      print('Error accessing camera: $e');
      if (_selectedVideoDeviceId != null) {
        setState(() => _selectedVideoDeviceId = null);
        await _initializeCamera();
      }
    }
  }

  Future<String> _getTempOutputFilePath() async {
    final dir = await getTemporaryDirectory();
    final timestamp = DateTime.now().millisecondsSinceEpoch;
    return '${dir.path}/recording_$timestamp.mp4';
  }

  String? _getFFmpegVideoInput() {
    if (_selectedVideoDeviceId == null) return null;

    final device = _videoDevices.firstWhere(
          (d) => d.deviceId == _selectedVideoDeviceId,
      orElse: () => MediaDeviceInfo(deviceId: '', label: '', kind: '', groupId: ''),
    );

    if (Platform.isWindows) {
      return device.label;
    } else if (Platform.isMacOS) {
      for (int i = 0; i < _videoDevices.length; i++) {
        if (_videoDevices[i].deviceId == _selectedVideoDeviceId) {
          return i.toString();
        }
      }
    }

    return null;
  }

  Future<void> _startRecording() async {
    if (_isRecording) return;
    if (widget.startCaptured != null){
      widget.startCaptured!();
    }

    // –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –∑–∞–ø–∏—Å–∏
    _recordingStartTime = DateTime.now();
    _allDetections.clear(); // –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏

    final tempPath = await _getTempOutputFilePath();
    _outputPath = tempPath;

    final videoInput = _getFFmpegVideoInput();

    if (videoInput == null) {
      print("No valid FFmpeg-compatible camera input.");
      return;
    }

    final command = Platform.isMacOS
        ? '-f avfoundation -framerate ${widget.frameRate} '
        '-video_size ${widget.videoWidth}x${widget.videoHeight} '
        '-i "$videoInput" -c:v libx264 -preset ultrafast -crf 23 '
        '-pix_fmt yuv420p "$tempPath"'
        : '-f dshow -i video="$videoInput" -nostdin '
        '-c:v libx264 -preset ultrafast -crf 23 '
        '-r ${widget.frameRate} "$tempPath"';


    print('Running FFmpeg command:\n$command');

    setState(() => _isRecording = true);

    _ffmpegSession = await FFmpegKit.executeAsync(command, (session) async {
      final returnCode = await session.getReturnCode();
      print('FFmpeg finished with code: $returnCode');

      setState(() {
        _isRecording = false;
        _ffmpegSession = null;
      });
      if (!File(tempPath).existsSync()) {
        print("‚ö†Ô∏è FFmpeg did not produce a file at: $tempPath");
      } else {
        print("‚úÖ File created: $tempPath");
      }
      if (returnCode != null && (ReturnCode.isSuccess(returnCode) || returnCode.getValue() == 255)) {
        if (File(tempPath).existsSync()) {
          print('Saving captured recording...');
          await _saveRecordedFile(tempPath);
        } else {
          print('Temp file not found after capture.');
        }
      } else {
        print('Recording failed with code: $returnCode');
        try {
          if (File(tempPath).existsSync()) await File(tempPath).delete();
        } catch (e) {
          print('Delete failed: $e');
        }
      }
    });}

// Replace _stopRecording with:
  Future<void> _stopRecording() async {
    if (!_isRecording || _ffmpegSession == null) return;

    print('üü• Attempting to stop recording...');
    setState(() => _isRecording = false);

    try {
      final session = _ffmpegSession;
      _ffmpegSession = null; // prevent reentrance

      // Cancel FFmpeg session
      await session!.cancel();
      print('‚úÖ FFmpeg session cancel called');

      // On Windows, force kill ffmpeg.exe if needed
      if (Platform.isWindows) {
        await Future.delayed(const Duration(seconds: 1)); // allow graceful shutdown
        final result = await Process.run('taskkill', ['/F', '/IM', 'ffmpeg.exe']);
        if (result.exitCode == 0) {
          print('‚úÖ Fallback: ffmpeg.exe force-killed');
        } else {
          print('‚ö†Ô∏è Fallback taskkill failed: ${result.stderr}');
        }
      }

    } catch (e) {
      print('‚ùå Error stopping recording: $e');
    }

    print('üü© Recording stop complete.');
  }

  Future<void> _saveRecordedFile(String tempFilePath) async {
    try {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
      final tempFile = File(tempFilePath);
      if (!await tempFile.exists()) {
        print('‚ùå Temp file does not exist: $tempFilePath');
        _showErrorSnackbar('Recording file not found');
        return;
      }

      // –ü–æ–ª—É—á–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
      String? saveDir = _defaultSaveFolder;
      if (saveDir == null || saveDir.isEmpty) {
        saveDir = await FilePicker.platform.getDirectoryPath();
        if (saveDir == null || saveDir.isEmpty) {
          print('User cancelled folder selection');
          return;
        }
        await _prefs?.setString('default_save_folder', saveDir);
      }

      // –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞
      final timestamp = DateTime.now().millisecondsSinceEpoch;
      final fileName = 'recording_$timestamp.mp4';
      final destination = path.join(saveDir, fileName);

      // –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–µ—Ç–µ–∫—Ü–∏–π
      try {
        if (_allDetections.isNotEmpty) {
          await _addDetectionsToVideo(tempFilePath, destination);
        } else {
          await tempFile.copy(destination);
        }

        print('‚úÖ Video saved to: $destination');

        // –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∏–¥–µ–æ –Ω–∞ —Å–µ—Ä–≤–µ—Ä, –µ—Å–ª–∏ –µ—Å—Ç—å examinationId
        if (widget.examinationId != null) {
          await _uploadVideoToServer(destination);
        }

        if (widget.onVideoCaptured != null) {
          widget.onVideoCaptured!(destination, _allDetections);
        }

        _showSuccessSnackbar('Video saved successfully', saveDir);
      } catch (e) {
        print('‚ùå Error processing video: $e');
        _showErrorSnackbar('Error processing video: $e');
      }
    } catch (e) {
      print('‚ùå Failed to save recording: $e');
      _showErrorSnackbar('Failed to save recording: $e');
    } finally {
      _allDetections.clear();
    }
  }

  void _showSuccessSnackbar(String message, String? directory) {
    if (!mounted) return;

    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(
        content: Text(message),
        backgroundColor: Colors.green,
        action: directory != null ? SnackBarAction(
          label: 'Open Folder',
          onPressed: () => _openFolder(directory),
        ) : null,
      ),
    );
  }

  void _showErrorSnackbar(String message) {
    if (!mounted) return;

    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(
        content: Text(message),
        backgroundColor: Colors.red,
      ),
    );
  }

  Future<void> _uploadVideoToServer(String filePath) async {
    if (widget.examinationId == null) return;

    try {
      if (!mounted) return;

      ScaffoldMessenger.of(context).showSnackBar(
        SnackBar(
          content: Row(
            children: [
              CircularProgressIndicator(
                strokeWidth: 2,
                valueColor: AlwaysStoppedAnimation<Color>(Colors.white),
              ),
              SizedBox(width: 10),
              Text('Uploading video to server...'),
            ],
          ),
          backgroundColor: Colors.orange,
          duration: Duration(seconds: 30),
        ),
      );

      final videoId = await ApiService.uploadVideoToExamination(
        widget.examinationId!,
        filePath,
      );

      if (!mounted) return;

      ScaffoldMessenger.of(context).clearSnackBars();

      if (videoId != null) {
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(
            content: Text('Video uploaded successfully!'),
            backgroundColor: Colors.green,
          ),
        );
      } else {
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(
            content: Text('Failed to upload video'),
            backgroundColor: Colors.orange,
          ),
        );
      }
    } catch (e) {
      print('‚ùå Error uploading video: $e');
      if (!mounted) return;

      ScaffoldMessenger.of(context).clearSnackBars();
      ScaffoldMessenger.of(context).showSnackBar(
        SnackBar(
          content: Text('Upload error: $e'),
          backgroundColor: Colors.red,
        ),
      );
    }
  }


// –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–µ—Ç–µ–∫—Ü–∏–π —Å —Ç–æ—á–Ω—ã–º–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
  Future<void> _addDetectionsToVideo(String inputPath, String outputPath) async {
    try {
      if (_allDetections.isEmpty) {
        await File(inputPath).copy(outputPath);
        return;
      }

      print('Processing ${_allDetections.length} detections with precise timing...');

      // –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
      _allDetections.sort((a, b) => a.timestamp.compareTo(b.timestamp));

      // –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–∫–∞–∑–∞ –∫–∞–∂–¥–æ–π –¥–µ—Ç–µ–∫—Ü–∏–∏
      // –ï—Å–ª–∏ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ø—Ä–∏—Ö–æ–¥—è—Ç –∫–∞–∂–¥—ã–µ 3 –∫–∞–¥—Ä–∞ –ø—Ä–∏ 30 FPS, —Ç–æ —ç—Ç–æ –∫–∞–∂–¥—ã–µ 0.1 —Å–µ–∫—É–Ω–¥—ã
      final detectionDuration = 3.0 / widget.frameRate; // ~0.1 —Å–µ–∫—É–Ω–¥—ã –¥–ª—è 30 FPS

      final allFilters = <String>[];

      // –°–æ–∑–¥–∞–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–π –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å —Ç–æ—á–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º
      for (final detection in _allDetections) {
        final startTime = detection.timestamp.inMilliseconds / 1000.0;
        final endTime = startTime + detectionDuration;

        // Drawbox —Ñ–∏–ª—å—Ç—Ä
        allFilters.add(detection.toFFmpegDrawbox(startTime: startTime, endTime: endTime));
        // Drawtext —Ñ–∏–ª—å—Ç—Ä
        allFilters.add(detection.toFFmpegDrawtext(startTime: startTime, endTime: endTime));
      }

      final filterComplex = allFilters.join(',');
      final command = '-i "$inputPath" -vf "$filterComplex" -c:v libx264 -preset ultrafast -crf 23 -c:a copy "$outputPath"';

      print('Running FFmpeg command with ${allFilters.length} filters');
      print('Detection duration: ${detectionDuration}s');

      final session = await FFmpegKit.execute(command);
      final returnCode = await session.getReturnCode();

      if (ReturnCode.isSuccess(returnCode)) {
        print('‚úÖ Video with precise detections processed successfully');
      } else {
        final logs = await session.getFailStackTrace();
        print('‚ùå FFmpeg error (code ${returnCode?.getValue()}): $logs');

        // Fallback: try without text labels
        await _addDetectionsToVideoBoxesOnly(inputPath, outputPath);
      }
    } catch (e) {
      print('‚ùå Error in precise FFmpeg processing: $e');
      await File(inputPath).copy(outputPath);
      rethrow;
    }
  }

// –ú–µ—Ç–æ–¥ —Ç–æ–ª—å–∫–æ —Å –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–∞–º–∏ (–±–µ–∑ —Ç–µ–∫—Å—Ç–∞) —Å —Ç–æ—á–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º
  Future<void> _addDetectionsToVideoBoxesOnly(String inputPath, String outputPath) async {
    try {
      print('Trying boxes-only approach with precise timing...');

      final detectionDuration = 3.0 / widget.frameRate;
      final boxFilters = <String>[];

      // –°–æ–∑–¥–∞–µ–º —Ç–æ–ª—å–∫–æ drawbox —Ñ–∏–ª—å—Ç—Ä—ã —Å —Ç–æ—á–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º
      for (final detection in _allDetections) {
        final startTime = detection.timestamp.inMilliseconds / 1000.0;
        final endTime = startTime + detectionDuration;

        boxFilters.add(detection.toFFmpegDrawbox(startTime: startTime, endTime: endTime));
      }

      final filterComplex = boxFilters.join(',');
      final command = '-i "$inputPath" -vf "$filterComplex" -c:v libx264 -preset ultrafast -crf 23 -c:a copy "$outputPath"';

      print('Running boxes-only FFmpeg command with precise timing');

      final session = await FFmpegKit.execute(command);
      final returnCode = await session.getReturnCode();

      if (ReturnCode.isSuccess(returnCode)) {
        print('‚úÖ Video with precise detection boxes processed successfully');
      } else {
        final logs = await session.getFailStackTrace();
        print('‚ùå Boxes-only FFmpeg error (code ${returnCode?.getValue()}): $logs');

        // Final fallback: save without detections
        await File(inputPath).copy(outputPath);
      }
    } catch (e) {
      print('‚ùå Error in boxes-only processing: $e');
      await File(inputPath).copy(outputPath);
      rethrow;
    }
  }

// –ú–µ—Ç–æ–¥ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –ø—Ä–∏ –∑–∞–ø–∏—Å–∏
  void _recordDetectionWithPreciseTime(DetectionBox detection) {
    // –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –∑–∞–ø–∏—Å–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–∞—á–∞–ª–∞
    final recordingStart = _recordingStartTime; // –ù—É–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —ç—Ç—É –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
    final currentTime = DateTime.now();
    final relativeTime = currentTime.difference(recordingStart!);

    // –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é —Å —Ç–æ—á–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º
    final preciseDetection = DetectionBox(
      x1: detection.x1,
      y1: detection.y1,
      x2: detection.x2,
      y2: detection.y2,
      label: detection.label,
      confidence: detection.confidence,
      timestamp: relativeTime, // –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è
    );

    if (_isRecording) {
      _allDetections.add(preciseDetection);
    }
  }

  Future<void> _openFolder(String folderPath) async {
    try {
      if (Platform.isWindows) {
        await Process.run('explorer', [folderPath]);
      } else if (Platform.isMacOS) {
        await Process.run('open', [folderPath]);
      }
    } catch (e) {
      print('Failed to open folder: $e');
    }
  }

  void _showSettingsDialog() {
    showDialog(
      context: context,
      builder: (context) => AlertDialog(
        title: const Text('Settings'),
        content: SizedBox(
          width: 500,
          child: Column(
            mainAxisSize: MainAxisSize.min,
            children: [
              const Text('Video Device:', style: TextStyle(fontWeight: FontWeight.bold)),
              const SizedBox(height: 8),
              DropdownButton<String>(
                isExpanded: true,
                value: _selectedVideoDeviceId,
                items: _videoDevices.map((device) {
                  return DropdownMenuItem(
                    value: device.deviceId,
                    child: Text(device.label.isNotEmpty ? device.label : 'Camera ${_videoDevices.indexOf(device) + 1}'),
                  );
                }).toList(),
                onChanged: (value) {
                  setState(() => _selectedVideoDeviceId = value);
                },
              ),
              const SizedBox(height: 10),

              const Text('Audio Device:', style: TextStyle(fontWeight: FontWeight.bold)),
              const SizedBox(height: 8),
              DropdownButton<String>(
                isExpanded: true,
                value: _selectedAudioDeviceId,
                items: _audioDevices.map((device) {
                  return DropdownMenuItem(
                    value: device.deviceId,
                    child: Text(device.label.isNotEmpty ? device.label : 'Microphone ${_audioDevices.indexOf(device) + 1}'),
                  );
                }).toList(),
                onChanged: (value) {
                  setState(() => _selectedAudioDeviceId = value);
                },
              ),
              const SizedBox(height: 16),

              const Text('Save Folder:', style: TextStyle(fontWeight: FontWeight.bold)),
              const SizedBox(height: 8),
              Row(
                children: [
                  Expanded(
                    child: Text(
                      _defaultSaveFolder?.isNotEmpty == true
                          ? _defaultSaveFolder!
                          : 'Not set (will prompt when saving)',
                      overflow: TextOverflow.ellipsis,
                    ),
                  ),
                  TextButton(
                    onPressed: () async {
                      final folder = await FilePicker.platform.getDirectoryPath();
                      if (folder != null) {
                        setState(() => _defaultSaveFolder = folder);
                      }
                    },
                    child: const Text('Browse'),
                  ),
                ],
              ),
            ],
          ),
        ),
        actions: [
          TextButton(
            onPressed: () => Navigator.pop(context),
            child: const Text('Cancel'),
          ),
          ElevatedButton(
            onPressed: () {
              _saveSettings();
              _initializeCamera();
              Navigator.pop(context);
            },
            child: const Text('Save'),
          ),
        ],
      ),
    );
  }

  @override
  void dispose() {
    _mediaStream?.getTracks().forEach((track) => track.stop());
    _renderer.dispose();
    _webSocketChannel?.sink.close();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    return SizedBox(
      width: widget.width,
      height: widget.height,
      child: Column(
        children: [
          // Video preview —Å –Ω–∞–ª–æ–∂–µ–Ω–∏–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏
          Expanded(
            flex: 1,
            child: Container(
              width: double.infinity,
              constraints: BoxConstraints(
                maxHeight: widget.height != null ? widget.height! - 80 : double.infinity,
              ),
              child: AspectRatio(
                aspectRatio: widget.aspectRatio,
                child: Container(
                  decoration: BoxDecoration(
                    color: Colors.black,
                    borderRadius: BorderRadius.circular(8),
                  ),
                  child: ClipRRect(
                    borderRadius: BorderRadius.circular(8),
                    child: Stack(
                      children: [
                        // –û—Å–Ω–æ–≤–Ω–æ–µ –≤–∏–¥–µ–æ
                        RTCVideoView(
                          _renderer,
                          objectFit: RTCVideoViewObjectFit.RTCVideoViewObjectFitCover,
                        ),
                        // –ù–∞–ª–æ–∂–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
                        if (_isDetectionEnabled && _currentDetections.isNotEmpty)
                          Positioned.fill(
                            child: CustomPaint(
                              painter: DetectionOverlayPainter(
                                detections: _currentDetections,
                                videoSize: Size(
                                  widget.videoWidth.toDouble(),
                                  widget.videoHeight.toDouble(),
                                ),
                              ),
                            ),
                          ),
                        // –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä —Å—Ç–∞—Ç—É—Å–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏
                        if (widget.examinationId != null)
                          Positioned(
                            top: 8,
                            right: 8,
                            child: Container(
                              padding: const EdgeInsets.symmetric(horizontal: 8, vertical: 4),
                              decoration: BoxDecoration(
                                color: _isDetectionEnabled ? Colors.green : Colors.grey,
                                borderRadius: BorderRadius.circular(12),
                              ),
                              child: Row(
                                mainAxisSize: MainAxisSize.min,
                                children: [
                                  Icon(
                                    _isDetectionEnabled ? Icons.visibility : Icons.visibility_off,
                                    color: Colors.white,
                                    size: 16,
                                  ),
                                  const SizedBox(width: 4),
                                  Text(
                                    _isDetectionEnabled ? 'AI ON' : 'AI OFF',
                                    style: const TextStyle(
                                      color: Colors.white,
                                      fontSize: 12,
                                      fontWeight: FontWeight.bold,
                                    ),
                                  ),
                                ],
                              ),
                            ),
                          ),
                      ],
                    ),
                  ),
                ),
              ),
            ),
          ),
          const SizedBox(height: 8),
          // –≠–ª–µ–º–µ–Ω—Ç—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
          Container(
            padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 8),
            child: SingleChildScrollView(
              scrollDirection: Axis.horizontal,
              child: Row(
                mainAxisAlignment: MainAxisAlignment.center,
                children: [
                  ElevatedButton.icon(
                    icon: Icon(_isRecording ? Icons.radio_button_checked : Icons.fiber_manual_record),
                    label: Text(_isRecording ? "Recording..." : "Start Recording"),
                    style: ElevatedButton.styleFrom(
                      backgroundColor: _isRecording ? Color(0xFFD9D9D9) : Color(0xFF00ACAB),
                      foregroundColor: Colors.white,
                      minimumSize: const Size(120, 36),
                    ),
                    onPressed: _isRecording ? null : _startRecording,
                  ),
                  const SizedBox(width: 12),
                  ElevatedButton.icon(
                    icon: const Icon(Icons.stop),
                    label: const Text("Stop Recording"),
                    style: ElevatedButton.styleFrom(
                      backgroundColor: Colors.grey.shade800,
                      foregroundColor: Colors.white,
                      minimumSize: const Size(120, 36),
                    ),
                    onPressed: _isRecording ? _stopRecording : null,
                  ),
                  const SizedBox(width: 12),
                  // –ö–Ω–æ–ø–∫–∞ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏
                  if (widget.examinationId != null)
                    ElevatedButton.icon(
                      icon: Icon(_isDetectionEnabled ? Icons.visibility : Icons.visibility_off),
                      label: Text(_isDetectionEnabled ? "AI ON" : "AI OFF"),
                      style: ElevatedButton.styleFrom(
                        backgroundColor: _isDetectionEnabled ? Colors.green : Colors.grey,
                        foregroundColor: Colors.white,
                        minimumSize: const Size(80, 36),
                      ),
                      onPressed: _toggleDetection,
                    ),
                  const SizedBox(width: 12),
                  IconButton(
                    color: Color(0xFF00ACAB),
                    icon: const Icon(Icons.settings),
                    onPressed: _showSettingsDialog,
                    tooltip: 'Settings',
                  ),
                ],
              ),
            ),
          ),
        ],
      ),
    );
  }
}